# ğŸš€ Unified LLM Platform

Eine All-in-One Plattform fÃ¼r Open-Source Large Language Models (LLMs) - optimiert fÃ¼r KVM Debian Root-Server.

## âœ¨ Features

- ğŸ¤– **Multi-Model Support**: Llama 3, Mistral, Qwen, Phi-3 und mehr
- ğŸ”Œ **OpenAI-kompatible API**: Drop-in Ersatz fÃ¼r OpenAI API
- ğŸ“ **Fine-Tuning**: LoRA/QLoRA Training integriert
- ğŸ–¥ï¸ **Web Interface**: Modernes Dashboard mit Chat & Monitoring
- ğŸ³ **Docker Ready**: Ein Befehl zum Starten
- ğŸ“Š **Monitoring**: Resource Tracking & Metrics
- ğŸ”’ **Sicher**: API Keys, Rate Limiting, CORS

## ğŸ¯ Quick Start

```bash
git clone https://github.com/hbrwhizz/unified-llm-platform.git
cd unified-llm-platform
chmod +x scripts/install.sh
./scripts/install.sh
docker-compose up -d
```

Ã–ffne: http://localhost:3000

## ğŸ“‹ Voraussetzungen

- Debian 11/12 oder Ubuntu 20.04+
- Docker & Docker Compose
- 16GB+ RAM (32GB empfohlen)
- NVIDIA GPU mit 8GB+ VRAM (optional, aber empfohlen)
- 100GB+ freier Speicherplatz

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web Interface  â”‚
â”‚   (React)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Nginx Proxy   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Server â”‚
â”‚  (Backend)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Engine   â”‚
â”‚ (Transformers)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤– UnterstÃ¼tzte Modelle

| Modell | Parameter | Quantisierung | Min. VRAM |
|--------|-----------|---------------|-----------|
| Llama 3.1 | 8B | 4-bit | 6GB |
| Mistral | 7B | 4-bit | 5GB |
| Qwen 2.5 | 7B | 4-bit | 5GB |
| Phi-3 | 3.8B | 4-bit | 3GB |

## ğŸ“š Dokumentation

- [Installation Guide](docs/INSTALLATION.md)
- [API Dokumentation](docs/API.md)
- [Fine-Tuning Guide](docs/FINE_TUNING.md)
- [Deployment Guide](docs/DEPLOYMENT.md)

## ğŸš€ Entwicklung

```bash
# Backend
cd backend
pip install -r requirements.txt
uvicorn main:app --reload

# Frontend
cd frontend
npm install
npm start
```

## ğŸ“ Lizenz

MIT License - siehe [LICENSE](LICENSE)

## ğŸ¤ Contributing

Contributions sind willkommen! Siehe [CONTRIBUTING.md](CONTRIBUTING.md)

## ğŸ“§ Support

- Issues: https://github.com/hbrwhizz/unified-llm-platform/issues
- Discussions: https://github.com/hbrwhizz/unified-llm-platform/discussions

---

**âš¡ Gebaut mit â¤ï¸ fÃ¼r die Open-Source LLM Community**